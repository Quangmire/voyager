name: "PC Voyager with Sequence Loss"
# Training Parameters
batch_size: 64
learning_rate: 0.001
learning_rate_decay: 2
min_learning_rate: 0.0001
num_epochs: 500
num_epochs_online: 20
steps_per_epoch: 80000
train_split: 0.8
valid_split: 0.1
multi_label: True
# Input Parameters
sequence_loss: True     # Train with sequence loss instead of cross entropy on last timestep
use_current_pc: True    # Feed in PC of current load instead of previous load at each timestep
sequence_length: 16
offset_bits: 6
prediction_depth: 0
global_stream: False
pc_localized: True
# LSTM Parameters
pc_embed_size: 64
page_embed_size: 128
num_experts: 100
lstm_size: 256
lstm_dropout: 0.8
lstm_layers: 1
# Output Parameters
global_output: False # By default, models predict the pc localized output
