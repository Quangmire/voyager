# Parameters for tuned Voyager.
#
# The idea is you generate one model for a multitude of traces.

meta:
    software_dirs:
        voyager: "/u/cmolder/GitHub/voyager/"
        champsim: "/u/cmolder/GitHub/ChampSim/"
    trace_dirs:
        load: "/scratch/cluster/qduong/ML-DPC/data/load_traces/"
        champsim: "/scratch/cluster/cmolder/ML-DPC/data/champsim_traces/"
    sweep_dir: "/scratch/cluster/cmolder/voyager_hypertuning/base/"
    use_gpu: true
    print_every: 100
    checkpoint_every: 10000
    champsim_print_every: 1 # million instructions 
traces: [
    "spec17/605.mcf-s0.txt.xz", # mcf
    #"spec17/605.mcf-s1.txt.xz", 
    #"spec17/605.mcf-s2.txt.xz", 
    #"spec17/605.mcf-s3.txt.xz", 
    #"spec17/605.mcf-s4.txt.xz", 
    #"spec17/605.mcf-s5.txt.xz", 
    #"spec17/605.mcf-s6.txt.xz", 
    #"spec17/605.mcf-s7.txt.xz", 
    "spec06/471.omnetpp-s0.txt.xz", # omnetpp
    #"spec06/471.omnetpp-s1.txt.xz",
    #"spec06/471.omnetpp-s2.txt.xz",
    "spec06/473.astar-s0.txt.xz" # astar
    #"spec06/473.astar-s1.txt.xz",
    #"spec06/473.astar-s2.txt.xz",
    #"gap/cc-5.txt.xz",  # cc
    #"gap/cc-6.txt.xz",
    #"gap/cc-13.txt.xz",
    #"gap/cc-14.txt.xz"
]
config: # If an array, it generates permutations of the values. Otherwise, it keeps them constant.
    name: "Base Voyager"
    # Training Parameters
    batch_size: 64
    learning_rate: 0.001
    learning_rate_decay: 2
    min_learning_rate: 0.0001
    num_epochs: 25
    num_epochs_online: 20
    steps_per_epoch: 80000
    train_split: 0.8
    valid_split: 0.1
    multi_label: False
    # Input Parameters
    sequence_loss: False    # Train with sequence loss instead of cross entropy on last timestep
    use_current_pc: False   # Feed in PC of current load instead of previous load at each timestep
    pc_localization: False  # Train on PC localized stream instead of global stream
    sequence_length: 16
    offset_bits: 6
    # LSTM Parameters
    pc_embed_size: 64
    page_embed_size: 128
    num_experts: 100
    lstm_size: 256
    lstm_dropout: 0.8
    lstm_layers: 1
