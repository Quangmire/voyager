name: "Base Voyager"
# Training Parameters
batch_size: 64
learning_rate: 0.001
learning_rate_decay: 2
min_learning_rate: 0.0001
num_epochs: 500
num_epochs_online: 20
steps_per_epoch: 80000
train_split: 0.8
valid_split: 0.1
multi_label: True
# Input Parameters
sequence_loss: False    # Train with sequence loss instead of cross entropy on last timestep
use_current_pc: False   # Feed in PC of current load instead of previous load at each timestep
pc_localization: False  # Train on PC localized stream instead of global stream
sequence_length: 16
offset_bits: 6
# LSTM Parameters
pc_embed_size: 64
page_embed_size: 128
num_experts: 100
lstm_size: 256
lstm_dropout: 0.8
lstm_layers: 1
